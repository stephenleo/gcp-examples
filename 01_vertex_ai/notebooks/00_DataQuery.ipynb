{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BigQuery data query"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  name,\n",
    "  gender,\n",
    "  COUNT(name) AS num_names\n",
    "FROM\n",
    "  `bigquery-public-data.usa_names.usa_1910_current`\n",
    "GROUP BY\n",
    "  name,\n",
    "  gender\n",
    "\"\"\"\n",
    "names_df = client.query(sql).to_dataframe()\n",
    "print(names_df.shape)\n",
    "names_df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(35236, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       name gender  num_names\n",
       "0      Mary      F       5597\n",
       "1     Annie      F       3994\n",
       "2      Anna      F       5566\n",
       "3  Margaret      F       5509\n",
       "4     Helen      F       4879"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>num_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mary</td>\n",
       "      <td>F</td>\n",
       "      <td>5597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annie</td>\n",
       "      <td>F</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anna</td>\n",
       "      <td>F</td>\n",
       "      <td>5566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Margaret</td>\n",
       "      <td>F</td>\n",
       "      <td>5509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Helen</td>\n",
       "      <td>F</td>\n",
       "      <td>4879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# write to csv\n",
    "names_df[['name', 'gender']].to_csv(\"../data/us-names.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Writing to sharded tfrecords"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def write_tfrecord(prefix, chunk, idx):\n",
    "    # Set writing options with compression\n",
    "    #options = tf.io.TFRecordOptions(compression_type=\"ZLIB\", compression_level=9)\n",
    "    options = None\n",
    "    \n",
    "    with tf.io.TFRecordWriter(\"../data/tfrecords/us_names_\"+prefix+\"_{:>03d}\".format(idx)+\".tfrecord\", options=options) as writer:       \n",
    "        for row in chunk.values:\n",
    "            features, label = row[:-1], row[-1]\n",
    "            \n",
    "            name = tf.train.Feature(bytes_list=tf.train.BytesList(value=[features[0].encode(\"utf-8\")]))\n",
    "            gender = tf.train.Feature(bytes_list=tf.train.BytesList(value=[label.encode(\"utf-8\")]))\n",
    "\n",
    "            data_dict = tf.train.Features(feature={\"name\": name, \"gender\": gender})\n",
    "            example = tf.train.Example(features=data_dict)\n",
    "\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "def serialize(chunk_df):\n",
    "    # Serializes inputs from a pandas dataset (read in chunks)   \n",
    "    # Write each chunk into individual tfrecord (sharding)\n",
    "    for idx, chunk in enumerate(chunk_df):\n",
    "        chunk.dropna(how=\"any\", inplace=True)\n",
    "        train_chunk, val_chunk, test_chunk = np.split(chunk.sample(frac=1), [int(.7*len(chunk)), int(.9*len(chunk))])\n",
    "\n",
    "        write_tfrecord(\"train\", train_chunk, idx)\n",
    "        write_tfrecord(\"val\", val_chunk, idx)\n",
    "        write_tfrecord(\"test\", test_chunk, idx)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%%time\n",
    "# Each chunk has 20K names\n",
    "names_df = pd.read_csv(\"../data/us-names.csv\", chunksize=20000, engine='c', iterator=True)\n",
    "serialize(names_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.11 s, sys: 3.33 ms, total: 1.11 s\n",
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "! gsutil cp ../data/tfrecords/*.tfrecord gs://leo-us-name-gender-us-central1/data/"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Copying file://../data/tfrecords/us_names_test_000.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://../data/tfrecords/us_names_test_001.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://../data/tfrecords/us_names_train_000.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://../data/tfrecords/us_names_train_001.tfrecord [Content-Type=application/octet-stream]...\n",
      "\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://../data/tfrecords/us_names_val_000.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://../data/tfrecords/us_names_val_001.tfrecord [Content-Type=application/octet-stream]...\n",
      "\n",
      "Operation completed over 6 objects/1.9 MiB.                                      \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('tf-gpu': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "d51a251884b5a170b1710e9e3b804db763c0c263ad29bc30d7f7babd6e5bff98"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}