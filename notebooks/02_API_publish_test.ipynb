{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_padding(inp, min_size=100):\n",
    "    # https://stackoverflow.com/questions/42334646/tensorflow-pad-unknown-size-tensor-to-a-specific-size\n",
    "    pad_size = min_size - tf.shape(inp)[0]\n",
    "    paddings = [[0, pad_size]] # Pad behind the name with spaces to align with padding from to_tensor default_value\n",
    "    return tf.pad(inp, paddings, mode=\"CONSTANT\", constant_values=\" \")\n",
    "\n",
    "def x_preprocess(x):\n",
    "    x_processed = tf.strings.lower(x)\n",
    "    x_processed = tf.strings.unicode_split(x_processed, input_encoding=\"UTF-8\").to_tensor(default_value=\" \") \n",
    "\n",
    "    # Pad only if necessary\n",
    "    filter_size = 100\n",
    "    x_processed = tf.cond(tf.less(tf.shape(x_processed)[1], filter_size), \n",
    "                        true_fn=lambda: tf.map_fn(lambda inp_name: dynamic_padding(inp_name, filter_size), x_processed), \n",
    "                        false_fn=lambda: tf.map_fn(lambda inp_name: tf.slice(inp_name, tf.constant([0]), tf.constant([100])), x_processed))\n",
    "\n",
    "    # Convert to number\n",
    "    x_processed = tf.strings.unicode_decode(x_processed, 'UTF-8')-96 # make a=1\n",
    "    x_processed = tf.map_fn(lambda item: (tf.map_fn(lambda subitem: 0 if (subitem[0]<0 or subitem[0]>26)else subitem[0], item)), x_processed.to_tensor()) # To remove negative value on space (32-96 = -64 and set the shape correctly)\n",
    "    x_processed = tf.cast(x_processed, tf.float32)\n",
    "    \n",
    "    return x_processed\n",
    "\n",
    "def to_tensor_format(input_name):\n",
    "    # Convert name to number\n",
    "    input_name = tf.constant(input_name)\n",
    "    x_processed = tf.map_fn(lambda name: x_preprocess([name]), input_name, dtype=tf.float32)\n",
    "\n",
    "    return x_processed\n",
    "\n",
    "def predict(instances, **kwargs):\n",
    "    imported = tf.saved_model.load(\"gs://leo-us-name-gender/model/1/\")\n",
    "    f = imported.signatures[\"serving_default\"]\n",
    "    \n",
    "    # Input Pre-Process\n",
    "    x_processed = to_tensor_format(instances)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = tf.map_fn(lambda x:f(x)[\"output\"], x_processed)\n",
    "    predictions = tf.map_fn(lambda pred: tf.squeeze(pred), predictions)\n",
    "\n",
    "\n",
    "    # Classes\n",
    "    class_names = tf.constant([\"F\", \"M\"], dtype=tf.string)\n",
    "\n",
    "    # Predictions are output from sigmoid so float32 in range 0 -> 1\n",
    "    # Round to integers for predicted class and string lookup for class name\n",
    "    prediction_integers = tf.cast(tf.math.round(predictions), tf.int32) \n",
    "    predicted_classes = tf.map_fn(lambda idx: class_names[idx], prediction_integers, dtype=tf.string)\n",
    "\n",
    "    # Convert sigmoid output for probability\n",
    "    # 1 (male) will remain at logit output\n",
    "    # 0 (female) will be 1.0 - logit to give probability\n",
    "    def to_probability(logit):\n",
    "        if logit < 0.5:\n",
    "            return 1.0 - logit\n",
    "        else:\n",
    "            return logit\n",
    "    class_probability = tf.map_fn(to_probability, predictions, dtype=tf.float32)\n",
    "\n",
    "    return {\n",
    "        \"gender\": [gender.decode(\"utf-8\") for gender in predicted_classes.numpy().tolist()],\n",
    "        \"probability\": class_probability.numpy().tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gender': ['M', 'F'], 'probability': [0.5780652761459351, 0.9435783624649048]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply = predict([\"stephen\", \"stephanie\"])\n",
    "reply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- To be Updated -----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': {'probability': [0.9067956805229187, 0.5227343440055847], 'gender': ['m', 'f']}}\n"
     ]
    }
   ],
   "source": [
    "from google.auth.transport import requests\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Construct service account credentials using the service account key file.\n",
    "credentials = service_account.Credentials.from_service_account_file('../credentials/ds-api-user.json')\n",
    "credentials = credentials.with_scopes(['https://www.googleapis.com/auth/cloud-platform'])\n",
    "\n",
    "# Create a requests Session object with the credentials.\n",
    "session = requests.AuthorizedSession(credentials)\n",
    "\n",
    "# Make an authenticated API request\n",
    "url = \"https://ml.googleapis.com/v1/projects/leo-gcp-sandbox/models/name_gender_prediction:predict\"\n",
    "json = {\"instances\":[{\"name\":\"stephen leo\"}, {\"name\":\"marie stephen leo\"}]}\n",
    "response = session.post(url, json=json)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a json string with ~100 names for scalability testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_df = names_df[names_df[\"gender\"]==\"F\"].sample(n=50)\n",
    "m_df = names_df[names_df[\"gender\"]==\"M\"].sample(n=50)\n",
    "names_sampled_df = pd.concat([f_df, m_df]).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {\"instances\": names_sampled_df[[\"name\"]].to_dict(\"records\")}\n",
    "import json\n",
    "with open(\"../data/names_100.json\", \"w\") as fp:\n",
    "    json.dump(names_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m71"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python [conda env:name_gender]",
   "language": "python",
   "name": "conda-env-name_gender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
